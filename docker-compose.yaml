version: "3.6"

services:
  spark-master:
    image: bitnami/spark:2.4.6
    container_name: spark-master
#    command: [
#        "spark-submit",
#        "--master", "spark://spark-master:7077",
#        "--conf", "spark.executors.memory=2g",
#        "--conf", "spark.driver.memory=2g",
#        "--class", "com.org.batch.Main",
#        "/home/bitnami/jars/batch-job-lib_2.11-2.4.6_0.1.jar",
#        "--reader-type", "csv",
#        "--writer-type", "mongodb",
#        "--transform-type", "no-op",
#        "--input-source", "file:///home/bitnami/data/movies_metadata.csv",
#        "--mongo-output-uri", "mongodb://db/movies.movies_metadata"
#    ]
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '40400:4040'
      - '48080:8080'

  spark-worker:
    image: bitnami/spark:2.4.6
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=4
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '48081:8081'
    volumes:
      - './src/resources/data/:/home/bitnami/data/:ro'
    depends_on:
      - spark-master
  db:
    image: bitnami/mongodb:latest
    container_name: mongodb
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    volumes:
      - './src/test/resources/integration_test/:/tmp/query/'

  livy:
    image: livy-image
    container_name: livy
    environment:
      - SPARK_MASTER_ENDPOINT=spark-master
      - SPARK_MASTER_PORT=7077
#      - LIVY_FILE_LOCAL_DIR_WHITELIST=/opt/jars
    ports:
      - "8998:8998"
    volumes:
      - './target/scala-2.11/batch-job-lib-assembly-0.1.jar:/opt/jars:ro'
    depends_on:
      - "spark-master"
      - "spark-worker"
