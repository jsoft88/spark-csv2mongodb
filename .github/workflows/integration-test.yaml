name: csv2mongodb-integration-testing
on: [pull_request, workflow_dispatch]
jobs:
  integration-test-job:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout project
        id: checkout-project
        uses: actions/checkout@v2
      - name: Create jar for spark
        id: create-spark-jar
        uses: lokkju/github-action-sbt@8-1.3.0-2.11.12
        with:
          commands: assembly
          sbt_project_directory: .
      - name: List target dir
        id: list-target-dir
        run: ls ./target/scala-2.11
      - name: Start docker compose spark master/executor and mongoDB
        id: start-docker-compose
        run: docker-compose up -d
      - name: Run spark execution
        id: run-spark-execution
        run: echo "::set-output name=run_spark::$(bash ./src/test/resources/integration_test/run_spark_job.sh)"
      - name: Poll spark job status
        id: poll-spark-job-status
        if: steps.run-spark-execution.outputs.run_spark == 'success'
        run: echo "::set-output name=spark_result::$(bash ./src/test/resources/integration_test/spark_job_polling.sh)"
      - name: Integration test failed
        id: integration-test-failed
        if: steps.poll-spark-job-status.outputs.spark_result == 'error'
        run: echo "Spark job failed, result is error"
      - name: Integration test passed
        if: steps.poll-spark-job-status.outputs.spark_result == 'success'
        run: echo "Integration test successful"